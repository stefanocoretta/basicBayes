{
  "hash": "22c388ff7f07b4344a0794f9a6991d7e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"04 - Bernoulli models for binary outcomes\"\nauthor: \"Stefano Coretta\"\n---\n\n\n\n\n\n## MALD: accuracy\n\n::: box-note\n-   **Accuracy of responses**: correctly or incorrectly recognised the word type (real or nonce-word).\n\n-   Let's model the effect of phonetic distance on accuracy.\n\n-   Accuracy is a **binary variable**.\n:::\n\n. . .\n\n::: box-tip\n-   With binary variables we model the probability of one of the two levels. Here, correct.\n\n-   The probability of one level of a binary variable follows a Bernoulli distribution.\n:::\n\n## Bernoulli model\n\n$$\np(correct) \\sim Bernoulli(p)\n$$\n\n. . .\n\n::: box-note\n-   But... probabilities are bounded between 0 and 1.\n\n-   For variables that can only have positive real numbers, we used the logarithmic function (log-normal models).\n:::\n\n. . .\n\n::: box-tip\n-   With probabilities, we can use the **logistic function**.\n\n-   The logistic (or logit) function converts probabilities to log-odds (`qlogis()` in R).\n:::\n\n## Logistic function\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Correspondence between log-odds and probabilities.](04-bernoulli_files/figure-revealjs/fig-p-log-odds-1.png){#fig-p-log-odds width=960}\n:::\n:::\n\n\n## Bernoulli (regression) models\n\n::: box-note\n-   Bernoulli models use the logistic function to treat probabilities as if they were unbounded.\n\n-   The model's estimates are in log-odds.\n\n-   Log-odds can be converted back to probabilities with the inverse logit function (`plogis()` in R).\n:::\n\n. . .\n\n::: box-warning\n-   Bernoulli models are also known as binomial or logistic regression.\n:::\n\n## A Bernoulli regression of accuracy: code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc_bern <- brm(\n  ACC ~ 1 + PhonLev,\n  family = bernoulli,\n  data = mald,\n  cores = 4,\n  seed = 8230,\n  file = \"data/cache/acc_bern\"\n)\n```\n:::\n\n\n## A Bernoulli regression of accuracy: predicted accuracy\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(acc_bern)\n```\n\n::: {.cell-output-display}\n![Predicted accuracy based on phonetic distance.](04-bernoulli_files/figure-revealjs/fig-acc-bern-cond-1.png){#fig-acc-bern-cond width=960}\n:::\n:::\n\n\n## Brentari 2024: Lengua de Señas Nicaragüense (LSN)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrentari2024 <- read_csv(\"data/brentari2024/verb_org.csv\")\n\nbrentari2024\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 630 × 6\n   Group    Participant Object   Number Agency   Num_Predicates\n   <chr>          <dbl> <chr>    <chr>  <chr>    <chr>         \n 1 homesign           1 book     single agent    multiple      \n 2 homesign           1 book     single agent    multiple      \n 3 homesign           1 book     plural no_agent multiple      \n 4 homesign           1 coin     single agent    single        \n 5 homesign           1 coin     plural no_agent single        \n 6 homesign           1 coin     single no_agent single        \n 7 homesign           1 coin     single no_agent multiple      \n 8 homesign           1 lollipop single agent    single        \n 9 homesign           1 lollipop single agent    single        \n10 homesign           1 lollipop plural no_agent single        \n# ℹ 620 more rows\n```\n\n\n:::\n:::\n\n\n## Brentari 2024\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrentari2024 |> \n  ggplot(aes(Group, fill = Num_Predicates)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"Proportion\")\n```\n\n::: {.cell-output-display}\n![Proportion of predicate type by group.](04-bernoulli_files/figure-revealjs/fig-prop-1.png){#fig-prop width=960}\n:::\n:::\n\n\n## A Bernoulli model of predicate type\n\n$$\n\\begin{align}\npred_i & \\sim Bernoulli(p_i)\\\\\nlogit(p_i) & = \\beta_1 \\cdot G_{\\text{HS}[i]} + \\beta_2 \\cdot G_{\\text{NSL1}[i]} + \\beta_3 \\cdot G_{\\text{NSL2}[i]}\n\\end{align}\n$$\n\n::: box-note\n-   `logit(p)` indicates a logit function is used (so the estimates are in log-odds).\n\n-   $G_{\\text{HS}[i]}, G_{\\text{NSL1}[i]},G_{\\text{NSL2}[i]}$ are **indicator variables**, a way of including categorical predictors in a regression model.\n:::\n\n## Indicator variables\n\n|          | $G_{\\text{HS}}$ | $G_{\\text{NSL1}}$ | $G_{\\text{NSL2}}$ |\n|----------|-----------------|-------------------|-------------------|\n| Homesign | 1               | 0                 | 0                 |\n| NSL1     | 0               | 1                 | 0                 |\n| NSL2     | 0               | 0                 | 1                 |\n\n. . .\n\n$$\n\\begin{align}\nlogit(p_i) & = \\beta_1 \\cdot G_{\\text{HS}[i]} + \\beta_2 \\cdot G_{\\text{NSL1}[i]} + \\beta_3 \\cdot G_{\\text{NSL2}[i]}\\\\\n\\text{homesign, } logit(p_i) & = \\beta_1 \\cdot 1 + \\beta_2 \\cdot 0 + \\beta_3 \\cdot 0\\\\\n& = \\beta_1\\\\\n\\text{NSL1, } logit(p_i) & = \\beta_1 \\cdot 0 + \\beta_2 \\cdot 1 + \\beta_3 \\cdot 0\\\\\n& = \\beta_2\\\\\n\\text{NSL2, } logit(p_i) & = \\beta_1 \\cdot 0 + \\beta_2 \\cdot 0 + \\beta_3 \\cdot 1\\\\\n& = \\beta_3\\\\\n\\end{align}\n$$\n\n## Indicator variables\n\n::: box-warning\n-   Note that indicator variables are dealt with by brms under the hood.\n\n-   We talk about them to understand how the model is set up.\n:::\n\n. . .\n\n::: box-note\n-   The model will estimate the probability $p$ for each group.\n\n-   But... the probability of what?\n:::\n\n## Prepare data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(brentari2024$Num_Predicates)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nmultiple   single \n     215      415 \n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrentari2024 <- brentari2024 |> \n  mutate(\n    Pred_Type = factor(Num_Predicates, levels = c(\"single\", \"multiple\"))\n  )\n\ntable(brentari2024$Pred_Type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  single multiple \n     415      215 \n```\n\n\n:::\n:::\n\n\n. . .\n\n::: box-tip\n-   The model will estimate the probability $p$ of finding a multiple predicate, depending on group.\n:::\n\n## A Bernoulli model of predicate type: suppress the intercept\n\n:::: box-note\n::: {style=\"text-align: center;\"}\n`v1_duration ~ 1 + speech_rate_c`\n:::\n\n- `1` stands for \"intercept\". The model has an intercept and a slope.\n::::\n\n. . .\n\n:::: box-note\n::: {style=\"text-align: center;\"}\n`Pred_Type ~ 0 + Group`\n:::\n\n- `0` stands for \"suppress the overall intercept\". The model estimates one \"intercept\" per level.\n::::\n\n## A Bernoulli model of predicate type: code\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_bern <- brm(\n  Pred_Type ~ 0 + Group,\n  family = bernoulli,\n  data = brentari2024,\n  cores = 4,\n  seed = 3218,\n  file = \"data/cache/pred_bern\"\n)\n```\n:::\n\n\n## A Bernoulli model of predicate type: summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(pred_bern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: Pred_Type ~ 0 + Group \n   Data: brentari2024 (Number of observations: 630) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nGrouphomesign    -0.57      0.16    -0.87    -0.26 1.00     4384     3351\nGroupNSL1        -1.46      0.17    -1.79    -1.14 1.00     4209     2946\nGroupNSL2        -0.02      0.14    -0.29     0.25 1.00     3865     2727\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## A Bernoulli model of predicate type: predicted probability\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(pred_bern)\n```\n\n::: {.cell-output-display}\n![Predicted probability of multiple predicate by group.](04-bernoulli_files/figure-revealjs/fig-pred-bern-cond-1.png){#fig-pred-bern-cond width=960}\n:::\n:::\n\n\n## Posterior draws\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_bern_draws <- as_draws_df(pred_bern)\n\npred_bern_draws\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A draws_df: 1000 iterations, 4 chains, and 5 variables\n   b_Grouphomesign b_GroupNSL1 b_GroupNSL2 lprior lp__\n1            -0.43        -1.6      -0.112      0 -381\n2            -0.17        -1.5      -0.049      0 -384\n3            -0.81        -1.4      -0.205      0 -383\n4            -0.52        -1.4      -0.110      0 -381\n5            -0.74        -1.4      -0.175      0 -382\n6            -0.21        -1.2       0.065      0 -384\n7            -0.89        -1.3      -0.037      0 -383\n8            -0.47        -1.3       0.095      0 -381\n9            -0.56        -1.3       0.081      0 -381\n10           -0.67        -1.5       0.048      0 -381\n# ... with 3990 more draws\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n\n\n:::\n:::\n\n\n## Credible intervals: log-odds\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(posterior)\n\npred_bern_draws |> \n  pivot_longer(b_Grouphomesign:b_GroupNSL2, names_to = \"coef\", values_to = \"est\") |> \n  group_by(coef) |> \n  summarise(\n    ci_lo = quantile2(est, probs = 0.025),\n    ci_hi = quantile2(est, probs = 0.975)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  coef             ci_lo  ci_hi\n  <chr>            <dbl>  <dbl>\n1 b_GroupNSL1     -1.79  -1.14 \n2 b_GroupNSL2     -0.292  0.250\n3 b_Grouphomesign -0.870 -0.257\n```\n\n\n:::\n:::\n\n\n## Credible intervals: probabilities\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_bern_draws |> \n  pivot_longer(b_Grouphomesign:b_GroupNSL2, names_to = \"coef\", values_to = \"est\") |> \n  group_by(coef) |> \n  summarise(\n    ci_lo = round(quantile2(plogis(est), probs = 0.025), 2),\n    ci_hi = round(quantile2(plogis(est), probs = 0.975), 2)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  coef            ci_lo ci_hi\n  <chr>           <dbl> <dbl>\n1 b_GroupNSL1      0.14  0.24\n2 b_GroupNSL2      0.43  0.56\n3 b_Grouphomesign  0.3   0.44\n```\n\n\n:::\n:::\n\n\n## What about comparing the groups?\n\n::: box-note\nWhat if we want to know the difference between each group?\n:::\n\n. . .\n\n::: box-tip\n- We can use the posterior draws. Simply take the row-wise difference and you will get a list of differences.\n\n- These are the posterior differences.\n:::\n\n## Comparing groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_bern_draws <- pred_bern_draws |> \n  mutate(\n    NSL1_homesign = b_GroupNSL1 - b_Grouphomesign,\n    NSL2_homesign = b_GroupNSL2 - b_Grouphomesign,\n    NSL2_NSL1 = b_GroupNSL2 - b_GroupNSL1\n  )\n\npred_bern_draws\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A draws_df: 1000 iterations, 4 chains, and 8 variables\n   b_Grouphomesign b_GroupNSL1 b_GroupNSL2 lprior lp__ NSL1_homesign\n1            -0.43        -1.6      -0.112      0 -381         -1.13\n2            -0.17        -1.5      -0.049      0 -384         -1.29\n3            -0.81        -1.4      -0.205      0 -383         -0.64\n4            -0.52        -1.4      -0.110      0 -381         -0.86\n5            -0.74        -1.4      -0.175      0 -382         -0.71\n6            -0.21        -1.2       0.065      0 -384         -1.04\n7            -0.89        -1.3      -0.037      0 -383         -0.44\n8            -0.47        -1.3       0.095      0 -381         -0.85\n9            -0.56        -1.3       0.081      0 -381         -0.78\n10           -0.67        -1.5       0.048      0 -381         -0.83\n   NSL2_homesign NSL2_NSL1\n1           0.32       1.4\n2           0.12       1.4\n3           0.61       1.2\n4           0.41       1.3\n5           0.56       1.3\n6           0.28       1.3\n7           0.85       1.3\n8           0.57       1.4\n9           0.64       1.4\n10          0.72       1.6\n# ... with 3990 more draws\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n\n\n:::\n:::\n\n\n## Credible Intervals of the difference: log-odds\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_bern_draws |> \n  pivot_longer(NSL1_homesign:NSL2_NSL1, names_to = \"coef\", values_to = \"est\") |> \n  group_by(coef) |> \n  summarise(\n    ci_lo = round(quantile2(est, probs = 0.025), 2),\n    ci_hi = round(quantile2(est, probs = 0.975), 2)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  coef          ci_lo ci_hi\n  <chr>         <dbl> <dbl>\n1 NSL1_homesign -1.34 -0.46\n2 NSL2_NSL1      1.03  1.87\n3 NSL2_homesign  0.11  0.95\n```\n\n\n:::\n:::\n\n\n## Credible Intervals of the difference: probabilities\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_bern_draws |> \n  mutate(\n    NSL1_homesign_p = plogis(b_GroupNSL1) - plogis(b_Grouphomesign),\n    NSL2_homesign_p = plogis(b_GroupNSL2) - plogis(b_Grouphomesign),\n    NSL2_NSL1_p = plogis(b_GroupNSL2) - plogis(b_GroupNSL1)\n  ) |> \n  pivot_longer(NSL1_homesign_p:NSL2_NSL1_p, names_to = \"coef\", values_to = \"est_p\") |> \n  group_by(coef) |> \n  summarise(\n    ci_lo = round(quantile2(est_p, probs = 0.025), 2),\n    ci_hi = round(quantile2(est_p, probs = 0.975), 2)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  coef            ci_lo ci_hi\n  <chr>           <dbl> <dbl>\n1 NSL1_homesign_p -0.26 -0.09\n2 NSL2_NSL1_p      0.22  0.39\n3 NSL2_homesign_p  0.03  0.23\n```\n\n\n:::\n:::\n\n\n## Summary\n\n::: box-tip\n- Binary variables can be modelled with a Bernoulli distribution.\n\n- Bernoulli models estimate the probability $p$ of the second level in the variable.\n\n- Categorical predictors are modelled using indexing variables.\n\n- You can obtain posterior differences between levels by taking the difference of the posterior draws of those levels.\n:::\n",
    "supporting": [
      "04-bernoulli_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}